#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  BRAIN SERVICE - Phoenix 95 Signal Intelligence Engine (í¬íŠ¸: 8100)
================================================================================
ì—­í• : Phoenix 95 AI ë¶„ì„ + ì‹ í˜¸ ì²˜ë¦¬ í†µí•©
ê¸°ëŠ¥: 85% ì´ìƒ ì‹ ë¢°ë„ ì‹ í˜¸ë§Œ í†µê³¼, Kelly Criterion í¬ì§€ì…˜ ì‚¬ì´ì§•
ê³ ë„í™”: RabbitMQ ë©”ì‹œì§€ ë°œí–‰, Redis Streams ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
================================================================================
"""

import asyncio
import json
import time
import logging
import hashlib
import hmac
import numpy as np
import redis
import aioredis
import pika
import aio_pika
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict, field
from collections import deque
import traceback
import gc
import psutil
import os
import sys
from pathlib import Path

# FastAPI ë° ì›¹ í”„ë ˆì„ì›Œí¬
from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends, Security, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import JSONResponse, HTMLResponse
from pydantic import BaseModel, Field, validator
import uvicorn

# =============================================================================
# ğŸ¯ BRAIN ì„œë¹„ìŠ¤ ì„¤ì •
# =============================================================================

@dataclass
class BrainServiceConfig:
    """ğŸ§  BRAIN ì„œë¹„ìŠ¤ ì „ìš© ì„¤ì •"""
    
    # ì„œë¹„ìŠ¤ ê¸°ë³¸ ì •ë³´
    SERVICE_NAME: str = "BRAIN"
    SERVICE_PORT: int = 8100
    SERVICE_VERSION: str = "4.0.0-BRAIN-ULTIMATE"
    
    # Phoenix 95 AI ì—”ì§„ ì„¤ì •
    PHOENIX_95_CONFIG: Dict[str, Any] = field(default_factory=lambda: {
        "confidence_threshold": 0.85,      # 85% ì´ìƒë§Œ í†µê³¼
        "analysis_timeout": 2.0,           # 2ì´ˆ ì´ë‚´ ë¶„ì„ ì™„ë£Œ
        "cache_duration": 300,             # 5ë¶„ ìºì‹œ
        "batch_size": 50,                  # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°
        "max_concurrent": 100,             # ìµœëŒ€ ë™ì‹œ ì²˜ë¦¬
        "retry_attempts": 3,               # ì¬ì‹œë„ íšŸìˆ˜
        "quality_threshold": 0.75,         # í’ˆì§ˆ ì„ê³„ê°’
        "model_ensemble": True,            # ì•™ìƒë¸” ëª¨ë¸ ì‚¬ìš©
        "real_time_validation": True       # ì‹¤ì‹œê°„ ê²€ì¦
    })
    
    # Kelly Criterion ì„¤ì •
    KELLY_CONFIG: Dict[str, Any] = field(default_factory=lambda: {
        "max_kelly_fraction": 0.25,        # ìµœëŒ€ 25% í¬ì§€ì…˜
        "min_kelly_fraction": 0.01,        # ìµœì†Œ 1% í¬ì§€ì…˜
        "win_rate_adjustment": 0.85,       # ìŠ¹ë¥  ì¡°ì • ê³„ìˆ˜
        "risk_free_rate": 0.02,            # ë¬´ìœ„í—˜ ìˆ˜ìµë¥ 
        "volatility_penalty": 0.1,         # ë³€ë™ì„± íŒ¨ë„í‹°
        "confidence_boost": 1.2            # ì‹ ë¢°ë„ ë¶€ìŠ¤íŠ¸
    })
    
    # ë©”ì‹œì§€ í ì„¤ì • (RabbitMQ)
    RABBITMQ_CONFIG: Dict[str, Any] = field(default_factory=lambda: {
        "host": "localhost",
        "port": 5672,
        "username": "phoenix95",
        "password": "secure_password_2025",
        "virtual_host": "/trading",
        "exchange": "phoenix95.brain.analysis",
        "routing_key": "signal.analyzed",
        "queue": "analyzed_signals",
        "durable": True,
        "auto_delete": False
    })
    
    # Redis Streams ì„¤ì •
    REDIS_CONFIG: Dict[str, Any] = field(default_factory=lambda: {
        "host": "localhost",
        "port": 6379,
        "db": 1,
        "stream_name": "brain:analysis:stream",
        "consumer_group": "brain_processors",
        "consumer_name": "brain-worker-1",
        "max_len": 10000,
        "block_ms": 1000
    })
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì„¤ì •
    MONITORING_CONFIG: Dict[str, Any] = field(default_factory=lambda: {
        "metrics_interval": 30,            # 30ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        "health_check_interval": 10,       # 10ì´ˆë§ˆë‹¤ í—¬ìŠ¤ì²´í¬
        "alert_thresholds": {
            "memory_percent": 80,
            "cpu_percent": 85,
            "queue_size": 1000,
            "error_rate": 5.0,
            "response_time_ms": 2000
        }
    })
    
    # í…”ë ˆê·¸ë¨ ì„¤ì •
    TELEGRAM_CONFIG: Dict[str, Any] = field(default_factory=lambda: {
        "token": "7386542811:AAEZ21p30rES1k8NxNM2xbZ53U44PI9D5CY",
        "chat_id": "7590895952",
        "enabled": True,
        "alert_level": "WARNING"
    })

# =============================================================================
# ğŸ“Š ë°ì´í„° ëª¨ë¸
# =============================================================================

@dataclass
class SignalData:
    """ì‹ í˜¸ ë°ì´í„° ëª¨ë¸"""
    signal_id: str
    symbol: str
    action: str
    price: float
    confidence: float
    timestamp: datetime
    
    # ê¸°ìˆ ì  ì§€í‘œ
    rsi: Optional[float] = None
    macd: Optional[float] = None
    bollinger_upper: Optional[float] = None
    bollinger_lower: Optional[float] = None
    volume: Optional[float] = None
    
    # ì¶”ê°€ ì •ë³´
    strategy: Optional[str] = None
    timeframe: Optional[str] = None
    source: Optional[str] = None
    
    def to_dict(self) -> Dict:
        return asdict(self)

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼ ëª¨ë¸"""
    signal_id: str
    symbol: str
    
    # ë¶„ì„ ì ìˆ˜
    phoenix95_score: float
    quality_score: float
    final_confidence: float
    
    # Kelly Criterion ê²°ê³¼
    kelly_fraction: float
    position_size: float
    
    # ë¦¬ìŠ¤í¬ í‰ê°€
    risk_level: str
    risk_score: float
    
    # ì‹¤í–‰ ê¶Œì¥
    recommendation: str
    execution_timing: str
    urgency: int
    
    # ë©”íƒ€ë°ì´í„°
    analysis_time_ms: float
    cache_hit: bool
    model_used: str
    
    # ìƒì„¸ ë¶„ì„
    technical_analysis: Dict = field(default_factory=dict)
    market_conditions: Dict = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        return asdict(self)

class SignalRequest(BaseModel):
    """ì‹ í˜¸ ìš”ì²­ ëª¨ë¸"""
    symbol: str = Field(..., description="ê±°ë˜ ì‹¬ë³¼")
    action: str = Field(..., description="ê±°ë˜ ë°©í–¥")
    price: float = Field(..., gt=0, description="ê°€ê²©")
    confidence: float = Field(0.8, ge=0, le=1, description="ì‹ ë¢°ë„")
    strategy: Optional[str] = Field(None, description="ì „ëµëª…")
    timeframe: Optional[str] = Field("1h", description="ì‹œê°„í”„ë ˆì„")
    rsi: Optional[float] = Field(None, description="RSI ì§€í‘œ")
    macd: Optional[float] = Field(None, description="MACD ì§€í‘œ")
    volume: Optional[float] = Field(None, description="ê±°ë˜ëŸ‰")
    
    @validator('action')
    def validate_action(cls, v):
        if v.lower() not in ['buy', 'sell', 'long', 'short']:
            raise ValueError('action must be buy, sell, long, or short')
        return v.lower()
    
    @validator('symbol')
    def validate_symbol(cls, v):
        return v.upper().strip()

# =============================================================================
# ğŸ§  Phoenix 95 AI Engine Core
# =============================================================================

class Phoenix95AIEngine:
    """ğŸ§  Phoenix 95 AI ì—”ì§„ - BRAIN ì„œë¹„ìŠ¤ ì½”ì–´"""
    
    def __init__(self, config: BrainServiceConfig):
        self.config = config
        self.phoenix_config = config.PHOENIX_95_CONFIG
        self.kelly_config = config.KELLY_CONFIG
        
        # ìºì‹œ ì‹œìŠ¤í…œ
        self.analysis_cache = {}
        self.market_data_cache = {}
        
        # ì„±ëŠ¥ ì¶”ì 
        self.performance_metrics = {
            "total_analyses": 0,
            "successful_analyses": 0,
            "cache_hits": 0,
            "avg_analysis_time": 0.0,
            "model_accuracy": 0.0
        }
        
        # ëª¨ë¸ ê°€ì¤‘ì¹˜ (Phoenix 95 ìµœì í™”)
        self.model_weights = {
            "technical_analysis": 0.35,
            "market_sentiment": 0.25,
            "volume_analysis": 0.20,
            "momentum_indicators": 0.20
        }
        
        logging.info("ğŸ§  Phoenix 95 AI Engine ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def analyze_signal_complete(self, signal: SignalData) -> AnalysisResult:
        """ğŸ¯ ì™„ì „í•œ ì‹ í˜¸ ë¶„ì„ - Phoenix 95 ë°©ì‹"""
        analysis_start = time.time()
        
        try:
            # 1. ìºì‹œ í™•ì¸
            cache_key = self._generate_cache_key(signal)
            cached_result = self._get_cached_analysis(cache_key)
            
            if cached_result:
                self.performance_metrics["cache_hits"] += 1
                cached_result.cache_hit = True
                return cached_result
            
            # 2. ì‹¤ì‹œê°„ ë°ì´í„° ê²€ì¦
            if self.phoenix_config["real_time_validation"]:
                validation_score = await self._validate_real_time_data(signal)
            else:
                validation_score = 0.8
            
            # 3. ê¸°ìˆ ì  ë¶„ì„
            technical_score, technical_details = await self._technical_analysis(signal)
            
            # 4. ì‹œì¥ ì¡°ê±´ ë¶„ì„
            market_score, market_conditions = await self._market_condition_analysis(signal)
            
            # 5. Phoenix 95 ì ìˆ˜ ê³„ì‚°
            phoenix95_score = await self._calculate_phoenix95_score(
                signal, technical_score, market_score, validation_score
            )
            
            # 6. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            quality_score = self._calculate_quality_score(
                signal, phoenix95_score, technical_score, market_score
            )
            
            # 7. ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            final_confidence = self._calculate_final_confidence(
                signal.confidence, phoenix95_score, quality_score
            )
            
            # 8. Kelly Criterion í¬ì§€ì…˜ ì‚¬ì´ì§•
            kelly_fraction, position_size = self._calculate_kelly_position(
                final_confidence, technical_details, market_conditions
            )
            
            # 9. ë¦¬ìŠ¤í¬ í‰ê°€
            risk_level, risk_score = self._assess_risk(
                signal, final_confidence, kelly_fraction, market_conditions
            )
            
            # 10. ì‹¤í–‰ ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendation, execution_timing, urgency = self._generate_recommendation(
                final_confidence, risk_level, phoenix95_score, quality_score
            )
            
            # 11. ë¶„ì„ ì‹œê°„ ê³„ì‚°
            analysis_time = (time.time() - analysis_start) * 1000
            
            # 12. ê²°ê³¼ ê°ì²´ ìƒì„±
            result = AnalysisResult(
                signal_id=signal.signal_id,
                symbol=signal.symbol,
                phoenix95_score=phoenix95_score,
                quality_score=quality_score,
                final_confidence=final_confidence,
                kelly_fraction=kelly_fraction,
                position_size=position_size,
                risk_level=risk_level,
                risk_score=risk_score,
                recommendation=recommendation,
                execution_timing=execution_timing,
                urgency=urgency,
                analysis_time_ms=analysis_time,
                cache_hit=False,
                model_used="Phoenix95_V4_Ultimate",
                technical_analysis=technical_details,
                market_conditions=market_conditions
            )
            
            # 13. ìºì‹œì— ì €ì¥
            self._cache_analysis(cache_key, result)
            
            # 14. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self._update_performance_metrics(result)
            
            # 15. í’ˆì§ˆ ì²´í¬ ë° ë¡œê¹…
            if final_confidence >= self.phoenix_config["confidence_threshold"]:
                logging.info(
                    f"ğŸ¯ ê³ í’ˆì§ˆ ì‹ í˜¸ ë¶„ì„ ì™„ë£Œ: {signal.symbol} "
                    f"Phoenix95={phoenix95_score:.3f} "
                    f"Final={final_confidence:.3f} "
                    f"Kelly={kelly_fraction:.3f} "
                    f"Time={analysis_time:.1f}ms"
                )
            else:
                logging.warning(
                    f"âš ï¸ ì €í’ˆì§ˆ ì‹ í˜¸: {signal.symbol} "
                    f"Final={final_confidence:.3f} < {self.phoenix_config['confidence_threshold']}"
                )
            
            return result
            
        except Exception as e:
            logging.error(f"ğŸ§  AI ë¶„ì„ ì‹¤íŒ¨: {signal.symbol} - {e}\n{traceback.format_exc()}")
            return self._create_fallback_result(signal, str(e), analysis_start)
    
    def _generate_cache_key(self, signal: SignalData) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_data = f"{signal.symbol}_{signal.action}_{signal.price}_{signal.confidence}_{signal.timestamp.hour}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _get_cached_analysis(self, cache_key: str) -> Optional[AnalysisResult]:
        """ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        if cache_key not in self.analysis_cache:
            return None
        
        cached_data, cached_time = self.analysis_cache[cache_key]
        cache_duration = self.phoenix_config["cache_duration"]
        
        if time.time() - cached_time > cache_duration:
            del self.analysis_cache[cache_key]
            return None
        
        return cached_data
    
    def _cache_analysis(self, cache_key: str, result: AnalysisResult):
        """ë¶„ì„ ê²°ê³¼ ìºì‹±"""
        self.analysis_cache[cache_key] = (result, time.time())
        
        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.analysis_cache) > 1000:
            oldest_key = min(self.analysis_cache.keys(), 
                           key=lambda k: self.analysis_cache[k][1])
            del self.analysis_cache[oldest_key]
    
    async def _validate_real_time_data(self, signal: SignalData) -> float:
        """ì‹¤ì‹œê°„ ë°ì´í„° ê²€ì¦"""
        try:
            # ì‹¤ì œ ê°€ê²© ì¡°íšŒ ì‹œë®¬ë ˆì´ì…˜
            current_price = signal.price * (1 + np.random.uniform(-0.01, 0.01))
            price_diff = abs(signal.price - current_price) / current_price
            
            if price_diff < 0.005:  # 0.5% ì´ë‚´
                return 0.95
            elif price_diff < 0.01:  # 1% ì´ë‚´
                return 0.85
            elif price_diff < 0.02:  # 2% ì´ë‚´
                return 0.70
            else:
                return 0.50
                
        except Exception as e:
            logging.warning(f"ì‹¤ì‹œê°„ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {e}")
            return 0.70
    
    async def _technical_analysis(self, signal: SignalData) -> Tuple[float, Dict]:
        """ê¸°ìˆ ì  ë¶„ì„"""
        technical_scores = []
        details = {}
        
        # RSI ë¶„ì„
        if signal.rsi is not None:
            rsi_score = self._analyze_rsi(signal.rsi, signal.action)
            technical_scores.append(rsi_score)
            details["rsi"] = {"value": signal.rsi, "score": rsi_score}
        
        # MACD ë¶„ì„
        if signal.macd is not None:
            macd_score = self._analyze_macd(signal.macd, signal.action)
            technical_scores.append(macd_score)
            details["macd"] = {"value": signal.macd, "score": macd_score}
        
        # ë³¼ë¦°ì € ë°´ë“œ ë¶„ì„
        if signal.bollinger_upper and signal.bollinger_lower:
            bb_score = self._analyze_bollinger_bands(
                signal.price, signal.bollinger_upper, signal.bollinger_lower, signal.action
            )
            technical_scores.append(bb_score)
            details["bollinger"] = {"score": bb_score}
        
        # ê±°ë˜ëŸ‰ ë¶„ì„
        if signal.volume:
            volume_score = self._analyze_volume(signal.volume)
            technical_scores.append(volume_score)
            details["volume"] = {"value": signal.volume, "score": volume_score}
        
        # ì¢…í•© ê¸°ìˆ ì  ì ìˆ˜
        if technical_scores:
            technical_score = np.mean(technical_scores)
        else:
            technical_score = signal.confidence * 0.8
        
        details["overall_score"] = technical_score
        details["indicators_count"] = len(technical_scores)
        
        return technical_score, details
    
    def _analyze_rsi(self, rsi: float, action: str) -> float:
        """RSI ë¶„ì„"""
        if action in ['buy', 'long']:
            if rsi <= 30:
                return 0.9
            elif rsi <= 40:
                return 0.7
            elif rsi <= 50:
                return 0.6
            elif rsi <= 60:
                return 0.4
            else:
                return 0.2
        else:  # sell, short
            if rsi >= 70:
                return 0.9
            elif rsi >= 60:
                return 0.7
            elif rsi >= 50:
                return 0.6
            elif rsi >= 40:
                return 0.4
            else:
                return 0.2
    
    def _analyze_macd(self, macd: float, action: str) -> float:
        """MACD ë¶„ì„"""
        if action in ['buy', 'long']:
            if macd > 0.01:
                return 0.8
            elif macd > 0:
                return 0.6
            elif macd > -0.005:
                return 0.4
            else:
                return 0.3
        else:  # sell, short
            if macd < -0.01:
                return 0.8
            elif macd < 0:
                return 0.6
            elif macd < 0.005:
                return 0.4
            else:
                return 0.3
    
    def _analyze_bollinger_bands(self, price: float, upper: float, lower: float, action: str) -> float:
        """ë³¼ë¦°ì € ë°´ë“œ ë¶„ì„"""
        bb_position = (price - lower) / (upper - lower) if upper != lower else 0.5
        
        if action in ['buy', 'long']:
            if bb_position <= 0.2:
                return 0.8
            elif bb_position <= 0.4:
                return 0.6
            elif bb_position <= 0.6:
                return 0.5
            else:
                return 0.3
        else:  # sell, short
            if bb_position >= 0.8:
                return 0.8
            elif bb_position >= 0.6:
                return 0.6
            elif bb_position >= 0.4:
                return 0.5
            else:
                return 0.3
    
    def _analyze_volume(self, volume: float) -> float:
        """ê±°ë˜ëŸ‰ ë¶„ì„"""
        # ê±°ë˜ëŸ‰ ì •ê·œí™” (ì‹¬ë³¼ë³„ í‰ê·  ê±°ë˜ëŸ‰ ëŒ€ë¹„)
        if volume > 10000000:
            return 0.9
        elif volume > 5000000:
            return 0.7
        elif volume > 1000000:
            return 0.6
        elif volume > 100000:
            return 0.4
        else:
            return 0.3
    
    async def _market_condition_analysis(self, signal: SignalData) -> Tuple[float, Dict]:
        """ì‹œì¥ ì¡°ê±´ ë¶„ì„"""
        conditions = {}
        scores = []
        
        # ì‹œê°„ëŒ€ ë¶„ì„
        hour = signal.timestamp.hour
        time_score = self._analyze_trading_hours(hour)
        scores.append(time_score)
        conditions["trading_hours"] = {"hour": hour, "score": time_score}
        
        # ìš”ì¼ ë¶„ì„
        weekday = signal.timestamp.weekday()
        weekday_score = self._analyze_weekday(weekday)
        scores.append(weekday_score)
        conditions["weekday"] = {"day": weekday, "score": weekday_score}
        
        # ë³€ë™ì„± ë¶„ì„ (ì‹œë®¬ë ˆì´ì…˜)
        volatility = np.random.uniform(0.1, 0.8)
        volatility_score = self._analyze_volatility(volatility)
        scores.append(volatility_score)
        conditions["volatility"] = {"value": volatility, "score": volatility_score}
        
        # ì‹œì¥ ì„¼í‹°ë©˜íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
        sentiment = np.random.uniform(0.2, 0.9)
        sentiment_score = sentiment
        scores.append(sentiment_score)
        conditions["sentiment"] = {"value": sentiment, "score": sentiment_score}
        
        market_score = np.mean(scores)
        conditions["overall_score"] = market_score
        
        return market_score, conditions
    
    def _analyze_trading_hours(self, hour: int) -> float:
        """ê±°ë˜ ì‹œê°„ëŒ€ ë¶„ì„"""
        if 8 <= hour <= 12:     # ì•„ì‹œì•„ ì˜¤ì „
            return 0.8
        elif 13 <= hour <= 17:  # ìœ ëŸ½ ì‹œê°„
            return 0.9
        elif 21 <= hour <= 1:   # ë¯¸êµ­ ì‹œê°„
            return 0.85
        elif 2 <= hour <= 6:    # ì €ì¡°í•œ ì‹œê°„
            return 0.3
        else:
            return 0.6
    
    def _analyze_weekday(self, weekday: int) -> float:
        """ìš”ì¼ ë¶„ì„"""
        weekday_scores = [0.8, 0.9, 0.9, 0.85, 0.7, 0.4, 0.3]  # ì›”~ì¼
        return weekday_scores[weekday]
    
    def _analyze_volatility(self, volatility: float) -> float:
        """ë³€ë™ì„± ë¶„ì„"""
        if 0.2 <= volatility <= 0.5:
            return 0.9  # ì ì • ë³€ë™ì„±
        elif 0.1 <= volatility < 0.2:
            return 0.6  # ë‚®ì€ ë³€ë™ì„±
        elif 0.5 < volatility <= 0.7:
            return 0.7  # ë†’ì€ ë³€ë™ì„±
        else:
            return 0.4  # ê·¹ë‹¨ì  ë³€ë™ì„±
    
    async def _calculate_phoenix95_score(self, signal: SignalData, technical_score: float, 
                                       market_score: float, validation_score: float) -> float:
        """Phoenix 95 ì ìˆ˜ ê³„ì‚°"""
        # ê¸°ë³¸ ì‹ ë¢°ë„ ë¶€ìŠ¤íŒ…
        base_confidence = signal.confidence
        boosted_confidence = min(base_confidence * self.kelly_config["confidence_boost"], 1.0)
        
        # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ Phoenix 95 ì ìˆ˜ ê³„ì‚°
        phoenix95_score = (
            boosted_confidence * 0.3 +
            technical_score * self.model_weights["technical_analysis"] +
            market_score * self.model_weights["market_sentiment"] +
            validation_score * 0.15
        )
        
        # ì‹œê°„ëŒ€ë³„ ë³´ì •
        hour_boost = self._get_hour_boost(signal.timestamp.hour)
        phoenix95_score *= hour_boost
        
        # ì‹¬ë³¼ë³„ ë³´ì •
        symbol_boost = self._get_symbol_boost(signal.symbol)
        phoenix95_score *= symbol_boost
        
        return min(max(phoenix95_score, 0.0), 1.0)
    
    def _get_hour_boost(self, hour: int) -> float:
        """ì‹œê°„ëŒ€ë³„ ë¶€ìŠ¤íŠ¸"""
        if 8 <= hour <= 12:
            return 1.05
        elif 13 <= hour <= 17:
            return 1.1
        elif 21 <= hour <= 1:
            return 1.08
        else:
            return 1.0
    
    def _get_symbol_boost(self, symbol: str) -> float:
        """ì‹¬ë³¼ë³„ ë¶€ìŠ¤íŠ¸"""
        major_symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT"]
        if symbol in major_symbols:
            return 1.05
        else:
            return 1.0
    
    def _calculate_quality_score(self, signal: SignalData, phoenix95_score: float, 
                               technical_score: float, market_score: float) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        # ì§€í‘œ ê°œìˆ˜ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤
        indicator_count = sum(1 for x in [signal.rsi, signal.macd, signal.volume] if x is not None)
        indicator_bonus = min(indicator_count * 0.05, 0.15)
        
        # ì‹ ë¢°ë„ ì¼ê´€ì„± ì²´í¬
        confidence_consistency = 1.0 - abs(signal.confidence - phoenix95_score) * 0.5
        
        # ìµœì¢… í’ˆì§ˆ ì ìˆ˜
        quality_score = (
            phoenix95_score * 0.4 +
            technical_score * 0.3 +
            market_score * 0.2 +
            confidence_consistency * 0.1 +
            indicator_bonus
        )
        
        return min(max(quality_score, 0.0), 1.0)
    
    def _calculate_final_confidence(self, original_confidence: float, 
                                  phoenix95_score: float, quality_score: float) -> float:
        """ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°"""
        # ê°€ì¤‘ í‰ê· 
        final_confidence = (
            original_confidence * 0.2 +
            phoenix95_score * 0.5 +
            quality_score * 0.3
        )
        
        return min(max(final_confidence, 0.0), 1.0)
    
    def _calculate_kelly_position(self, confidence: float, technical_details: Dict, 
                                market_conditions: Dict) -> Tuple[float, float]:
        """Kelly Criterion í¬ì§€ì…˜ ì‚¬ì´ì§•"""
        # ìŠ¹ë¥  ì¶”ì •
        win_probability = confidence * self.kelly_config["win_rate_adjustment"]
        
        # ì†ìµë¹„ ì¶”ì •
        expected_return = 1.02  # 2% ìˆ˜ìµ ëª©í‘œ
        expected_loss = 0.98    # 2% ì†ì‹¤ í•œë„
        
        # ë³€ë™ì„± ì¡°ì •
        volatility = market_conditions.get("volatility", {}).get("value", 0.3)
        volatility_adjustment = max(0.5, 1 - volatility * self.kelly_config["volatility_penalty"])
        
        # Kelly ê³µì‹
        kelly_fraction = (
            (win_probability * expected_return - (1 - win_probability)) / expected_return
        ) * volatility_adjustment
        
        # í•œê³„ê°’ ì ìš©
        kelly_fraction = max(
            self.kelly_config["min_kelly_fraction"],
            min(kelly_fraction, self.kelly_config["max_kelly_fraction"])
        )
        
        # í¬ì§€ì…˜ í¬ê¸° (ê¸°ë³¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ìœ¨)
        position_size = kelly_fraction
        
        return kelly_fraction, position_size
    
    def _assess_risk(self, signal: SignalData, confidence: float, kelly_fraction: float, 
                    market_conditions: Dict) -> Tuple[str, float]:
        """ë¦¬ìŠ¤í¬ í‰ê°€"""
        risk_factors = []
        
        # ì‹ ë¢°ë„ ë¦¬ìŠ¤í¬
        if confidence < 0.6:
            risk_factors.append(0.3)
        elif confidence < 0.8:
            risk_factors.append(0.1)
        
        # Kelly í¬ì§€ì…˜ ë¦¬ìŠ¤í¬
        if kelly_fraction > 0.15:
            risk_factors.append(0.2)
        elif kelly_fraction > 0.1:
            risk_factors.append(0.1)
        
        # ì‹œì¥ ì¡°ê±´ ë¦¬ìŠ¤í¬
        market_score = market_conditions.get("overall_score", 0.5)
        if market_score < 0.5:
            risk_factors.append(0.2)
        elif market_score < 0.7:
            risk_factors.append(0.1)
        
        # ë³€ë™ì„± ë¦¬ìŠ¤í¬
        volatility = market_conditions.get("volatility", {}).get("value", 0.3)
        if volatility > 0.6:
            risk_factors.append(0.25)
        elif volatility > 0.4:
            risk_factors.append(0.1)
        
        # ì¢…í•© ë¦¬ìŠ¤í¬ ì ìˆ˜
        risk_score = sum(risk_factors)
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •
        if risk_score <= 0.2:
            risk_level = "LOW"
        elif risk_score <= 0.4:
            risk_level = "MEDIUM"
        elif risk_score <= 0.6:
            risk_level = "HIGH"
        else:
            risk_level = "VERY_HIGH"
        
        return risk_level, risk_score
    
    def _generate_recommendation(self, confidence: float, risk_level: str, 
                               phoenix95_score: float, quality_score: float) -> Tuple[str, str, int]:
        """ì‹¤í–‰ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        # ì¶”ì²œ ê²°ì •
        if (confidence >= self.phoenix_config["confidence_threshold"] and 
            risk_level in ["LOW", "MEDIUM"] and 
            phoenix95_score >= 0.75):
            recommendation = "STRONG_BUY" if phoenix95_score >= 0.9 else "BUY"
            execution_timing = "IMMEDIATE"
            urgency = min(10, int(confidence * 10))
        elif (confidence >= 0.7 and 
              risk_level in ["LOW", "MEDIUM"] and 
              quality_score >= self.phoenix_config["quality_threshold"]):
            recommendation = "WEAK_BUY"
            execution_timing = "CAREFUL"
            urgency = min(7, int(confidence * 8))
        elif confidence >= 0.6 and risk_level != "VERY_HIGH":
            recommendation = "HOLD"
            execution_timing = "MONITOR"
            urgency = min(5, int(confidence * 6))
        else:
            recommendation = "REJECT"
            execution_timing = "HOLD"
            urgency = 1
        
        return recommendation, execution_timing, urgency
    
    def _create_fallback_result(self, signal: SignalData, error: str, start_time: float) -> AnalysisResult:
        """ì˜¤ë¥˜ì‹œ ëŒ€ì²´ ê²°ê³¼ ìƒì„±"""
        analysis_time = (time.time() - start_time) * 1000
        
        return AnalysisResult(
            signal_id=signal.signal_id,
            symbol=signal.symbol,
            phoenix95_score=0.0,
            quality_score=0.0,
            final_confidence=0.0,
            kelly_fraction=0.01,
            position_size=0.01,
            risk_level="VERY_HIGH",
            risk_score=1.0,
            recommendation="REJECT",
            execution_timing="HOLD",
            urgency=0,
            analysis_time_ms=analysis_time,
            cache_hit=False,
            model_used="FALLBACK",
            technical_analysis={"error": error},
            market_conditions={"error": error}
        )
    
    def _update_performance_metrics(self, result: AnalysisResult):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        self.performance_metrics["total_analyses"] += 1
        
        if result.recommendation != "REJECT":
            self.performance_metrics["successful_analyses"] += 1
        
        # ì´ë™ í‰ê· ìœ¼ë¡œ ë¶„ì„ ì‹œê°„ ì—…ë°ì´íŠ¸
        total = self.performance_metrics["total_analyses"]
        current_avg = self.performance_metrics["avg_analysis_time"]
        new_avg = (current_avg * (total - 1) + result.analysis_time_ms) / total
        self.performance_metrics["avg_analysis_time"] = new_avg
    
    def get_performance_summary(self) -> Dict:
        """ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ"""
        total = self.performance_metrics["total_analyses"]
        success_rate = (
            self.performance_metrics["successful_analyses"] / total * 100 
            if total > 0 else 0
        )
        cache_hit_rate = (
            self.performance_metrics["cache_hits"] / total * 100 
            if total > 0 else 0
        )
        
        return {
            "total_analyses": total,
            "success_rate": round(success_rate, 2),
            "cache_hit_rate": round(cache_hit_rate, 2),
            "avg_analysis_time_ms": round(self.performance_metrics["avg_analysis_time"], 2),
            "cache_size": len(self.analysis_cache)
        }

# =============================================================================
# ğŸ“¡ ë©”ì‹œì§€ í & ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
# =============================================================================

class MessageQueuePublisher:
    """RabbitMQ ë©”ì‹œì§€ ë°œí–‰ì"""
    
    def __init__(self, config: BrainServiceConfig):
        self.config = config.RABBITMQ_CONFIG
        self.connection = None
        self.channel = None
        self.connected = False
    
    async def connect(self):
        """RabbitMQ ì—°ê²°"""
        try:
            connection_params = aio_pika.ConnectionParameters(
                host=self.config["host"],
                port=self.config["port"],
                login=self.config["username"],
                password=self.config["password"],
                virtual_host=self.config["virtual_host"]
            )
            
            self.connection = await aio_pika.connect_robust(
                host=self.config["host"],
                port=self.config["port"],
                login=self.config["username"],
                password=self.config["password"],
                virtualhost=self.config["virtual_host"]
            )
            
            self.channel = await self.connection.channel()
            
            # Exchange ìƒì„±
            self.exchange = await self.channel.declare_exchange(
                self.config["exchange"],
                aio_pika.ExchangeType.DIRECT,
                durable=self.config["durable"]
            )
            
            # Queue ìƒì„±
            self.queue = await self.channel.declare_queue(
                self.config["queue"],
                durable=self.config["durable"]
            )
            
            await self.queue.bind(self.exchange, self.config["routing_key"])
            
            self.connected = True
            logging.info("ğŸ° RabbitMQ ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            logging.error(f"ğŸ° RabbitMQ ì—°ê²° ì‹¤íŒ¨: {e}")
            self.connected = False
    
    async def publish_analysis_result(self, signal: SignalData, result: AnalysisResult):
        """ë¶„ì„ ê²°ê³¼ ë°œí–‰"""
        if not self.connected:
            await self.connect()
        
        if not self.connected:
            logging.warning("ğŸ° RabbitMQ ì—°ê²° ì‹¤íŒ¨ - ë©”ì‹œì§€ ë°œí–‰ ë¶ˆê°€")
            return
        
        try:
            message_data = {
                "signal": signal.to_dict(),
                "analysis": result.to_dict(),
                "timestamp": time.time(),
                "service": "BRAIN"
            }
            
            message = aio_pika.Message(
                json.dumps(message_data).encode(),
                content_type="application/json",
                delivery_mode=aio_pika.DeliveryMode.PERSISTENT
            )
            
            await self.exchange.publish(
                message,
                routing_key=self.config["routing_key"]
            )
            
            logging.info(f"ğŸ“¤ ë¶„ì„ ê²°ê³¼ ë°œí–‰: {signal.symbol} -> {result.recommendation}")
            
        except Exception as e:
            logging.error(f"ğŸ“¤ ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: {e}")
    
    async def disconnect(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.connection:
            await self.connection.close()
            self.connected = False
            logging.info("ğŸ° RabbitMQ ì—°ê²° ì¢…ë£Œ")

class RedisStreamPublisher:
    """Redis Streams ë°œí–‰ì"""
    
    def __init__(self, config: BrainServiceConfig):
        self.config = config.REDIS_CONFIG
        self.redis = None
        self.connected = False
    
    async def connect(self):
        """Redis ì—°ê²°"""
        try:
            self.redis = await aioredis.from_url(
                f"redis://{self.config['host']}:{self.config['port']}/{self.config['db']}"
            )
            
            # ìŠ¤íŠ¸ë¦¼ì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
            try:
                await self.redis.xgroup_create(
                    self.config["stream_name"],
                    self.config["consumer_group"],
                    id="0",
                    mkstream=True
                )
            except Exception:
                pass  # ê·¸ë£¹ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°
            
            self.connected = True
            logging.info("ğŸ”´ Redis Streams ì—°ê²° ì„±ê³µ")
            
        except Exception as e:
            logging.error(f"ğŸ”´ Redis Streams ì—°ê²° ì‹¤íŒ¨: {e}")
            self.connected = False
    
    async def publish_stream_data(self, signal: SignalData, result: AnalysisResult):
        """ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ë°œí–‰"""
        if not self.connected:
            await self.connect()
        
        if not self.connected:
            logging.warning("ğŸ”´ Redis Streams ì—°ê²° ì‹¤íŒ¨ - ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ë¶ˆê°€")
            return
        
        try:
            stream_data = {
                "signal_id": signal.signal_id,
                "symbol": signal.symbol,
                "action": signal.action,
                "price": str(signal.price),
                "phoenix95_score": str(result.phoenix95_score),
                "final_confidence": str(result.final_confidence),
                "recommendation": result.recommendation,
                "kelly_fraction": str(result.kelly_fraction),
                "risk_level": result.risk_level,
                "timestamp": str(time.time()),
                "service": "BRAIN"
            }
            
            message_id = await self.redis.xadd(
                self.config["stream_name"],
                stream_data,
                maxlen=self.config["max_len"]
            )
            
            logging.info(f"ğŸŒŠ ìŠ¤íŠ¸ë¦¼ ë°ì´í„° ë°œí–‰: {signal.symbol} ID={message_id}")
            
        except Exception as e:
            logging.error(f"ğŸŒŠ ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹¤íŒ¨: {e}")
    
    async def disconnect(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.redis:
            await self.redis.close()
            self.connected = False
            logging.info("ğŸ”´ Redis Streams ì—°ê²° ì¢…ë£Œ")

# =============================================================================
# ğŸ§  BRAIN ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤
# =============================================================================

class BrainService:
    """ğŸ§  BRAIN ì„œë¹„ìŠ¤ - Phoenix 95 Signal Intelligence Engine"""
    
    def __init__(self):
        self.config = BrainServiceConfig()
        self.app = FastAPI(
            title="ğŸ§  BRAIN Service - Phoenix 95 AI Engine",
            description="Phoenix 95 Signal Intelligence Engine (í¬íŠ¸: 8100)",
            version=self.config.SERVICE_VERSION
        )
        
        # CORS ì„¤ì •
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.ai_engine = Phoenix95AIEngine(self.config)
        self.mq_publisher = MessageQueuePublisher(self.config)
        self.stream_publisher = RedisStreamPublisher(self.config)
        
        # ì„œë¹„ìŠ¤ ìƒíƒœ
        self.service_stats = {
            "start_time": time.time(),
            "total_requests": 0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "active_connections": 0
        }
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬
        self.background_tasks = []
        
        # ë¼ìš°íŠ¸ ì„¤ì •
        self._setup_routes()
        
        logging.info(f"ğŸ§  BRAIN ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (í¬íŠ¸: {self.config.SERVICE_PORT})")
    
    def _setup_routes(self):
        """ë¼ìš°íŠ¸ ì„¤ì •"""
        
        @self.app.get("/")
        async def root():
            return HTMLResponse(self._generate_dashboard_html())
        
        @self.app.get("/health")
        async def health_check():
            """í—¬ìŠ¤ì²´í¬"""
            uptime = time.time() - self.service_stats["start_time"]
            
            return {
                "service": "BRAIN",
                "status": "healthy",
                "version": self.config.SERVICE_VERSION,
                "uptime_seconds": round(uptime, 2),
                "total_requests": self.service_stats["total_requests"],
                "ai_engine_ready": True,
                "rabbitmq_connected": self.mq_publisher.connected,
                "redis_connected": self.stream_publisher.connected,
                "performance": self.ai_engine.get_performance_summary(),
                "timestamp": time.time()
            }
        
        @self.app.post("/analyze")
        async def analyze_signal(request: SignalRequest, background_tasks: BackgroundTasks):
            """ğŸ¯ ì‹ í˜¸ ë¶„ì„ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸"""
            try:
                self.service_stats["total_requests"] += 1
                analysis_start = time.time()
                
                # SignalData ê°ì²´ ìƒì„±
                signal = SignalData(
                    signal_id=f"BRAIN_{int(time.time() * 1000)}",
                    symbol=request.symbol,
                    action=request.action,
                    price=request.price,
                    confidence=request.confidence,
                    timestamp=datetime.utcnow(),
                    rsi=request.rsi,
                    macd=request.macd,
                    volume=request.volume,
                    strategy=request.strategy,
                    timeframe=request.timeframe,
                    source="API"
                )
                
                # AI ë¶„ì„ ì‹¤í–‰
                analysis_result = await self.ai_engine.analyze_signal_complete(signal)
                
                # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë©”ì‹œì§€ ë°œí–‰
                background_tasks.add_task(self._publish_results, signal, analysis_result)
                
                # ì„±ê³µ í†µê³„ ì—…ë°ì´íŠ¸
                if analysis_result.recommendation != "REJECT":
                    self.service_stats["successful_analyses"] += 1
                else:
                    self.service_stats["failed_analyses"] += 1
                
                # ì‘ë‹µ ìƒì„±
                processing_time = (time.time() - analysis_start) * 1000
                
                response = {
                    "status": "success",
                    "signal_id": signal.signal_id,
                    "symbol": signal.symbol,
                    "analysis": {
                        "phoenix95_score": analysis_result.phoenix95_score,
                        "quality_score": analysis_result.quality_score,
                        "final_confidence": analysis_result.final_confidence,
                        "recommendation": analysis_result.recommendation,
                        "execution_timing": analysis_result.execution_timing,
                        "urgency": analysis_result.urgency,
                        "risk_level": analysis_result.risk_level,
                        "risk_score": analysis_result.risk_score
                    },
                    "position_sizing": {
                        "kelly_fraction": analysis_result.kelly_fraction,
                        "position_size": analysis_result.position_size
                    },
                    "performance": {
                        "analysis_time_ms": analysis_result.analysis_time_ms,
                        "processing_time_ms": round(processing_time, 2),
                        "cache_hit": analysis_result.cache_hit,
                        "model_used": analysis_result.model_used
                    },
                    "service_info": {
                        "service": "BRAIN",
                        "version": self.config.SERVICE_VERSION,
                        "timestamp": time.time()
                    }
                }
                
                # ê³ í’ˆì§ˆ ì‹ í˜¸ ë¡œê¹…
                if analysis_result.final_confidence >= self.config.PHOENIX_95_CONFIG["confidence_threshold"]:
                    logging.info(
                        f"ğŸ¯ ê³ í’ˆì§ˆ ì‹ í˜¸ ë¶„ì„: {signal.symbol} "
                        f"Confidence={analysis_result.final_confidence:.3f} "
                        f"Recommendation={analysis_result.recommendation}"
                    )
                
                return response
                
            except Exception as e:
                self.service_stats["failed_analyses"] += 1
                logging.error(f"ğŸ§  ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: {e}\n{traceback.format_exc()}")
                
                raise HTTPException(
                    status_code=500,
                    detail={
                        "error": "ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨",
                        "message": str(e),
                        "service": "BRAIN"
                    }
                )
        
        @self.app.get("/stats")
        async def get_statistics():
            """ì„œë¹„ìŠ¤ í†µê³„ ì¡°íšŒ"""
            uptime = time.time() - self.service_stats["start_time"]
            ai_performance = self.ai_engine.get_performance_summary()
            
            return {
                "service": "BRAIN",
                "version": self.config.SERVICE_VERSION,
                "uptime_seconds": round(uptime, 2),
                "service_stats": self.service_stats,
                "ai_performance": ai_performance,
                "connections": {
                    "rabbitmq": self.mq_publisher.connected,
                    "redis_streams": self.stream_publisher.connected
                },
                "timestamp": time.time()
            }
        
        @self.app.get("/config")
        async def get_configuration():
            """ì„œë¹„ìŠ¤ ì„¤ì • ì¡°íšŒ"""
            return {
                "service": "BRAIN",
                "phoenix95_config": self.config.PHOENIX_95_CONFIG,
                "kelly_config": self.config.KELLY_CONFIG,
                "monitoring_config": self.config.MONITORING_CONFIG,
                "version": self.config.SERVICE_VERSION
            }
    
    async def _publish_results(self, signal: SignalData, result: AnalysisResult):
        """ë¶„ì„ ê²°ê³¼ ë°œí–‰ (ë°±ê·¸ë¼ìš´ë“œ)"""
        try:
            # RabbitMQ ë°œí–‰
            await self.mq_publisher.publish_analysis_result(signal, result)
            
            # Redis Streams ë°œí–‰
            await self.stream_publisher.publish_stream_data(signal, result)
            
            logging.info(f"ğŸ“¡ ê²°ê³¼ ë°œí–‰ ì™„ë£Œ: {signal.symbol} -> {result.recommendation}")
            
        except Exception as e:
            logging.error(f"ğŸ“¡ ê²°ê³¼ ë°œí–‰ ì‹¤íŒ¨: {e}")
    
    def _generate_dashboard_html(self) -> str:
        """ëŒ€ì‹œë³´ë“œ HTML ìƒì„±"""
        uptime = time.time() - self.service_stats["start_time"]
        uptime_str = str(timedelta(seconds=int(uptime)))
        ai_performance = self.ai_engine.get_performance_summary()
        
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>ğŸ§  BRAIN Service Dashboard</title>
            <meta charset="utf-8">
            <meta name="viewport" content="width=device-width, initial-scale=1">
            <style>
                body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 0; background: linear-gradient(135deg, #1e3c72, #2a5298); color: #fff; }}
                .container {{ max-width: 1200px; margin: 0 auto; padding: 20px; }}
                .header {{ text-align: center; margin-bottom: 30px; }}
                .header h1 {{ font-size: 2.5em; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.5); }}
                .header p {{ font-size: 1.2em; opacity: 0.9; }}
                .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
                .stat-card {{ background: rgba(255,255,255,0.1); backdrop-filter: blur(10px); border-radius: 15px; padding: 25px; border: 1px solid rgba(255,255,255,0.2); }}
                .stat-title {{ font-size: 1.4em; font-weight: bold; margin-bottom: 20px; color: #00ff88; text-shadow: 1px 1px 2px rgba(0,0,0,0.5); }}
                .stat-item {{ display: flex; justify-content: space-between; margin: 12px 0; padding: 8px 0; border-bottom: 1px solid rgba(255,255,255,0.1); }}
                .stat-value {{ color: #00ff88; font-weight: bold; font-size: 1.1em; }}
                .status-indicator {{ display: inline-block; width: 12px; height: 12px; border-radius: 50%; margin-right: 8px; animation: pulse 2s infinite; }}
                .status-healthy {{ background: #00ff88; box-shadow: 0 0 10px #00ff88; }}
                .status-warning {{ background: #ffa500; box-shadow: 0 0 10px #ffa500; }}
                .footer {{ text-align: center; margin-top: 40px; opacity: 0.7; }}
                @keyframes pulse {{ 0% {{ opacity: 1; }} 50% {{ opacity: 0.5; }} 100% {{ opacity: 1; }} }}
                .refresh-info {{ text-align: center; margin: 20px 0; opacity: 0.8; }}
            </style>
            <script>
                setInterval(() => location.reload(), 30000);
            </script>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ§  BRAIN Service</h1>
                    <p>Phoenix 95 Signal Intelligence Engine</p>
                    <p><span class="status-indicator status-healthy"></span>ì„œë¹„ìŠ¤ ìƒíƒœ: ì •ìƒ ìš´ì˜ì¤‘ | ì—…íƒ€ì„: {uptime_str}</p>
                </div>
                
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-title">ğŸ“Š ì„œë¹„ìŠ¤ í†µê³„</div>
                        <div class="stat-item">
                            <span>í¬íŠ¸:</span>
                            <span class="stat-value">{self.config.SERVICE_PORT}</span>
                        </div>
                        <div class="stat-item">
                            <span>ì´ ìš”ì²­:</span>
                            <span class="stat-value">{self.service_stats["total_requests"]:,}</span>
                        </div>
                        <div class="stat-item">
                            <span>ì„±ê³µí•œ ë¶„ì„:</span>
                            <span class="stat-value">{self.service_stats["successful_analyses"]:,}</span>
                        </div>
                        <div class="stat-item">
                            <span>ì‹¤íŒ¨í•œ ë¶„ì„:</span>
                            <span class="stat-value">{self.service_stats["failed_analyses"]:,}</span>
                        </div>
                        <div class="stat-item">
                            <span>ë²„ì „:</span>
                            <span class="stat-value">{self.config.SERVICE_VERSION}</span>
                        </div>
                    </div>
                    
                    <div class="stat-card">
                        <div class="stat-title">ğŸ§  AI ì—”ì§„ ì„±ëŠ¥</div>
                        <div class="stat-item">
                            <span>ì´ ë¶„ì„ ìˆ˜:</span>
                            <span class="stat-value">{ai_performance["total_analyses"]:,}</span>
                        </div>
                        <div class="stat-item">
                            <span>ì„±ê³µë¥ :</span>
                            <span class="stat-value">{ai_performance["success_rate"]}%</span>
                        </div>
                        <div class="stat-item">
                            <span>ìºì‹œ íˆíŠ¸ìœ¨:</span>
                            <span class="stat-value">{ai_performance["cache_hit_rate"]}%</span>
                        </div>
                        <div class="stat-item">
                            <span>í‰ê·  ë¶„ì„ ì‹œê°„:</span>
                            <span class="stat-value">{ai_performance["avg_analysis_time_ms"]}ms</span>
                        </div>
                        <div class="stat-item">
                            <span>ìºì‹œ í¬ê¸°:</span>
                            <span class="stat-value">{ai_performance["cache_size"]}</span>
                        </div>
                    </div>
                    
                    <div class="stat-card">
                        <div class="stat-title">ğŸ“¡ ì—°ê²° ìƒíƒœ</div>
                        <div class="stat-item">
                            <span>RabbitMQ:</span>
                            <span class="stat-value">{"âœ… ì—°ê²°ë¨" if self.mq_publisher.connected else "âŒ ì—°ê²° ì•ˆë¨"}</span>
                        </div>
                        <div class="stat-item">
                            <span>Redis Streams:</span>
                            <span class="stat-value">{"âœ… ì—°ê²°ë¨" if self.stream_publisher.connected else "âŒ ì—°ê²° ì•ˆë¨"}</span>
                        </div>
                        <div class="stat-item">
                            <span>ìŠ¤íŠ¸ë¦¼:</span>
                            <span class="stat-value">{self.config.REDIS_CONFIG["stream_name"]}</span>
                        </div>
                        <div class="stat-item">
                            <span>Exchange:</span>
                            <span class="stat-value">{self.config.RABBITMQ_CONFIG["exchange"]}</span>
                        </div>
                    </div>
                    
                    <div class="stat-card">
                        <div class="stat-title">âš™ï¸ ì„¤ì • ì •ë³´</div>
                        <div class="stat-item">
                            <span>ì‹ ë¢°ë„ ì„ê³„ê°’:</span>
                            <span class="stat-value">{self.config.PHOENIX_95_CONFIG["confidence_threshold"]:.1%}</span>
                        </div>
                        <div class="stat-item">
                            <span>í’ˆì§ˆ ì„ê³„ê°’:</span>
                            <span class="stat-value">{self.config.PHOENIX_95_CONFIG["quality_threshold"]:.1%}</span>
                        </div>
                        <div class="stat-item">
                            <span>ë¶„ì„ ì œí•œì‹œê°„:</span>
                            <span class="stat-value">{self.config.PHOENIX_95_CONFIG["analysis_timeout"]}ì´ˆ</span>
                        </div>
                        <div class="stat-item">
                            <span>ìµœëŒ€ Kelly:</span>
                            <span class="stat-value">{self.config.KELLY_CONFIG["max_kelly_fraction"]:.1%}</span>
                        </div>
                        <div class="stat-item">
                            <span>ìºì‹œ ì§€ì†ì‹œê°„:</span>
                            <span class="stat-value">{self.config.PHOENIX_95_CONFIG["cache_duration"]}ì´ˆ</span>
                        </div>
                    </div>
                </div>
                
                <div class="refresh-info">
                    <p>ğŸ”„ 30ì´ˆë§ˆë‹¤ ìë™ ìƒˆë¡œê³ ì¹¨ | ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                </div>
                
                <div class="footer">
                    <p>ğŸ§  BRAIN Service - Phoenix 95 Signal Intelligence Engine</p>
                    <p>85% ì´ìƒ ì‹ ë¢°ë„ ì‹ í˜¸ ì²˜ë¦¬ | Kelly Criterion í¬ì§€ì…˜ ì‚¬ì´ì§• | ì‹¤ì‹œê°„ ë©”ì‹œì§€ í ì—°ë™</p>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html
    
    async def start_background_services(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì‹œì‘"""
        logging.info("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì‹œì‘")
        
        # ë©”ì‹œì§€ í ì—°ê²°
        await self.mq_publisher.connect()
        
        # Redis Streams ì—°ê²°
        await self.stream_publisher.connect()
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ íƒœìŠ¤í¬
        monitor_task = asyncio.create_task(self._performance_monitoring_loop())
        self.background_tasks.append(monitor_task)
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ íƒœìŠ¤í¬
        cleanup_task = asyncio.create_task(self._memory_cleanup_loop())
        self.background_tasks.append(cleanup_task)
        
        logging.info(f"âœ… {len(self.background_tasks)}ê°œ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹œì‘ë¨")
    
    async def _performance_monitoring_loop(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(self.config.MONITORING_CONFIG["metrics_interval"])
                
                # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
                memory_percent = psutil.virtual_memory().percent
                cpu_percent = psutil.cpu_percent()
                
                # ì•Œë¦¼ ì„ê³„ê°’ ì²´í¬
                alerts = []
                thresholds = self.config.MONITORING_CONFIG["alert_thresholds"]
                
                if memory_percent > thresholds["memory_percent"]:
                    alerts.append(f"ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {memory_percent:.1f}%")
                
                if cpu_percent > thresholds["cpu_percent"]:
                    alerts.append(f"ë†’ì€ CPU ì‚¬ìš©ë¥ : {cpu_percent:.1f}%")
                
                ai_performance = self.ai_engine.get_performance_summary()
                if ai_performance["avg_analysis_time_ms"] > thresholds["response_time_ms"]:
                    alerts.append(f"ëŠë¦° ì‘ë‹µì‹œê°„: {ai_performance['avg_analysis_time_ms']:.1f}ms")
                
                # ì•Œë¦¼ ë¡œê¹…
                for alert in alerts:
                    logging.warning(f"âš ï¸ BRAIN ì„±ëŠ¥ ì•Œë¦¼: {alert}")
                
            except Exception as e:
                logging.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}")
    
    async def _memory_cleanup_loop(self):
        """ë©”ëª¨ë¦¬ ì •ë¦¬ ë£¨í”„"""
        while True:
            try:
                await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤
                
                # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                collected = gc.collect()
                
                # ìºì‹œ ì •ë¦¬
                current_time = time.time()
                cache_duration = self.config.PHOENIX_95_CONFIG["cache_duration"]
                
                expired_keys = [
                    key for key, (_, timestamp) in self.ai_engine.analysis_cache.items()
                    if current_time - timestamp > cache_duration
                ]
                
                for key in expired_keys:
                    del self.ai_engine.analysis_cache[key]
                
                if collected > 0 or expired_keys:
                    logging.info(f"ğŸ§¹ ë©”ëª¨ë¦¬ ì •ë¦¬: GC={collected}, ìºì‹œ={len(expired_keys)}")
                
            except Exception as e:
                logging.error(f"ë©”ëª¨ë¦¬ ì •ë¦¬ ì˜¤ë¥˜: {e}")
    
    async def stop_background_services(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì •ì§€"""
        logging.info("ğŸ›‘ ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì •ì§€")
        
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì·¨ì†Œ
        for task in self.background_tasks:
            task.cancel()
        
        # ì—°ê²° ì¢…ë£Œ
        await self.mq_publisher.disconnect()
        await self.stream_publisher.disconnect()
        
        logging.info("âœ… ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì •ì§€ ì™„ë£Œ")

# =============================================================================
# ğŸš€ ë©”ì¸ ì‹¤í–‰ë¶€
# =============================================================================

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - [ğŸ§ BRAIN] %(message)s',
            handlers=[
                logging.FileHandler('brain_service.log', encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        
        # BRAIN ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        brain_service = BrainService()
        
        # ë°±ê·¸ë¼ìš´ë“œ ì„œë¹„ìŠ¤ ì‹œì‘
        await brain_service.start_background_services()
        
        # ì‹œì‘ ë©”ì‹œì§€
        logging.info("ğŸ§  BRAIN Service ì‹œì‘")
        logging.info(f"ğŸ“¡ í¬íŠ¸: {brain_service.config.SERVICE_PORT}")
        logging.info(f"ğŸ¯ Phoenix 95 ì‹ ë¢°ë„ ì„ê³„ê°’: {brain_service.config.PHOENIX_95_CONFIG['confidence_threshold']:.1%}")
        logging.info(f"ğŸ“Š í’ˆì§ˆ ì„ê³„ê°’: {brain_service.config.PHOENIX_95_CONFIG['quality_threshold']:.1%}")
        logging.info(f"ğŸ° RabbitMQ: {'âœ…' if brain_service.mq_publisher.connected else 'âŒ'}")
        logging.info(f"ğŸ”´ Redis: {'âœ…' if brain_service.stream_publisher.connected else 'âŒ'}")
        
        # ì„œë²„ ì‹¤í–‰
        config = uvicorn.Config(
            brain_service.app,
            host="0.0.0.0",
            port=brain_service.config.SERVICE_PORT,
            log_level="info",
            access_log=True
        )
        
        server = uvicorn.Server(config)
        await server.serve()
        
    except KeyboardInterrupt:
        logging.info("ğŸ›‘ ì‚¬ìš©ìì— ì˜í•œ ì„œë¹„ìŠ¤ ì¢…ë£Œ")
    except Exception as e:
        logging.error(f"âŒ ì„œë¹„ìŠ¤ ì‹¤í–‰ ì˜¤ë¥˜: {e}\n{traceback.format_exc()}")
    finally:
        # ì •ë¦¬
        if 'brain_service' in locals():
            await brain_service.stop_background_services()
        logging.info("ğŸ‘‹ BRAIN Service ì¢…ë£Œ")

if __name__ == "__main__":
    asyncio.run(main())

# =============================================================================
# ğŸ“‹ ì‚¬ìš©ë²• ë° API ì˜ˆì œ
# =============================================================================

"""
ğŸ§  BRAIN Service ì‚¬ìš©ë²•:

1. ì„œë¹„ìŠ¤ ì‹œì‘:
   python brain_service.py

2. API í˜¸ì¶œ ì˜ˆì œ:
   curl -X POST "http://localhost:8100/analyze" \
        -H "Content-Type: application/json" \
        -d '{
            "symbol": "BTCUSDT",
            "action": "buy",
            "price": 45000.0,
            "confidence": 0.8,
            "rsi": 35.5,
            "macd": 0.003,
            "volume": 1500000
        }'

3. í—¬ìŠ¤ì²´í¬:
   curl http://localhost:8100/health

4. í†µê³„ ì¡°íšŒ:
   curl http://localhost:8100/stats

5. ëŒ€ì‹œë³´ë“œ ì ‘ì†:
   http://localhost:8100

ğŸ“¡ ë©”ì‹œì§€ í ì„¤ì •:
- RabbitMQ Exchange: phoenix95.brain.analysis
- Redis Stream: brain:analysis:stream
- ë¶„ì„ ê²°ê³¼ê°€ ìë™ìœ¼ë¡œ ë‹¤ë¥¸ ì„œë¹„ìŠ¤ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.

ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
- Phoenix 95 AI ë¶„ì„ (85% ì´ìƒ ì‹ ë¢°ë„)
- Kelly Criterion í¬ì§€ì…˜ ì‚¬ì´ì§•
- ì‹¤ì‹œê°„ ë°ì´í„° ê²€ì¦
- ê¸°ìˆ ì  ì§€í‘œ ë¶„ì„
- ì‹œì¥ ì¡°ê±´ í‰ê°€
- ë¦¬ìŠ¤í¬ ë ˆë²¨ ì‚°ì •
- ì‹¤í–‰ ê¶Œì¥ì‚¬í•­ ìƒì„±
- RabbitMQ ë©”ì‹œì§€ ë°œí–‰
- Redis Streams ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- ìë™ ìºì‹œ ê´€ë¦¬
"""